# Preparing Data

ModelSkill requires data in `Observation` and `ModelResult` objects. These objects are inputs for ModelSkill's `Comparer`, which matches data and assesses skill. This section covers `PointObservation` and `PointModelResult` for comparing time series at specific points.

```{python}
#| echo: false
#| output: false
#| warning: false
#| message: false
import mikeio
import mikeio1d
import modelskill as ms
import pandas as pd
import os # For file cleanup
```

## Observations

A `PointObservation` represents measured data, often a time series from one sensor. Each object handles one point and variable. For API details, see the [PointObservation documentation](https://dhi.github.io/modelskill/api/PointObservation.html).

Key parameters for `PointObservation`:

| Parameter  | Description                                                                                                                                                                                                                            |
|------------|----------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `name`     | A unique identifier (e.g., "Gauge_A_WaterLevel"). Useful for distinguishing observations and labeling plots.                                                                                                                              |
| `data`     | The data source: a `dfs0` file path, MIKE IO `Dataset`, or Pandas `DataFrame`.                                                                                                                                              |
| `item`     | Specifies the data column (for Pandas `DataFrame`) or item (for MIKE IO `Dataset` or `dfs0` path) from the source. Refer by name (string) or numerical index.      |
| `quantity` | A `modelskill.Quantity` defining the variable `name` (e.g., "Water Level") and `unit` (e.g., "m"). Essential if the data source (e.g., Pandas `DataFrame`) lacks this metadata. ModelSkill often infers this from `dfs0` files with EUM information. |

::: {.callout-tip title="Understanding the Quantity object in ModelSkill" collapse="true"}
The `quantity` parameter (`ms.Quantity(name="...", unit="...")`) is vital for ModelSkill. It defines the data's variable (e.g., "Water Level," "Discharge") and unit (e.g., "m," "m^3/s"). This information is used for:

1.  Clear plot labeling.
2.  Compatibility checks between observations and model results.

ModelSkill often infers `quantity` from `dfs0` files with EUM information. For other sources like Pandas DataFrames or CSV files, you **must** define `quantity` explicitly.

Consult the [ModelSkill documentation on Quantity](https://dhi.github.io/modelskill/api/Quantity.html) for details, including EUM handling and more examples.
:::

::: {.callout-tip title="Coordinates (x, y) for a PointObservation" collapse="true"}
ModelSkill examples often include `x` and `y` coordinates for `PointObservation` objects. ModelSkill uses these coordinates mainly to interpolate data from spatial model outputs (e.g., `dfsu`, `dfs2` files) to the observation point. This is useful for comparing point observations to 2D or 3D model fields.

This module focuses on comparing time series already extracted for specific points (e.g., from a `res1d` node to `dfs0`, or a point sensor `dfs0`). Thus, we won't use the `x` and `y` spatial interpolation capability extensively here.
:::

### From Dataset

First, read a `dfs0` file into a MIKE IO `Dataset`.
```{python}
ds_obs = mikeio.read("data/flow_meter_data.dfs0")
ds_obs
```

Create a `PointObservation` from this `Dataset`, selecting one item.
```{python}
obs_116l1 = ms.PointObservation(
    data=ds_obs,
    item="116l1_observed",    # Selects one column/item
    name="116l1_Gauge",       # Descriptive name for this specific observation
)
obs_116l1
```

A `PointObservation` has useful attributes and methods. Plot to verify:
```{python}
obs_116l1.plot()
```

### From dfs0 file

Alternatively, create a `PointObservation` using the `dfs0` file path directly:
```{python}
obs_116l1_from_file = ms.PointObservation(
    data="data/flow_meter_data.dfs0",
    item="116l1_observed",
    name="116l1_Gauge",
)
obs_116l1_from_file.to_dataframe().head()
```

### From Pandas DataFrame

First, prepare a Pandas `DataFrame`.
```{python}
df_obs_csv = pd.read_csv("data/flow_meter_data.csv", index_col="time", parse_dates=True)
df_obs_csv.head()
```

Create a `PointObservation` from the `DataFrame`. Provide `quantity` as DataFrames lack EUM information.
```{python}
obs_12l1_from_df = ms.PointObservation(
    data=df_obs_csv,
    item="12l1_observed",
    name="12l1_Gauge",
    quantity=ms.Quantity(name="Discharge", unit="m^3/s"),
)
obs_12l1_from_df.plot()
```

::: {.callout-note}
Ensure DataFrames have a `DatetimeIndex`, as mentioned in previous modules.
:::

## Model Results

`PointModelResult` objects represent model simulation outputs. Each `PointModelResult` handles one variable from a specific model output point and represents a model simulation run. See the [PointModelResult documentation](https://dhi.github.io/modelskill/api/PointModelResult.html) for API details.

Key parameters for `PointModelResult` are similar to `PointObservation`:

| Parameter  | Description                                                                                                                                                                                                                                                                                                                                                                                                                     |
|------------|---------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|
| `name`     | Identifies the model simulation run (e.g., "MIKE_Plus_Scenario_A").                                                                                                                                                                                                                                                                             |
| `data`     | The data source: a `dfs0` file path, MIKE IO `Dataset`, or Pandas `DataFrame`.                                                                                                                                                                                                                                                          |
| `item`     | Specifies the data column (for Pandas `DataFrame`) or item (for MIKE IO `Dataset` or `dfs0` path) from the source.                                                                                                                                                                                                                                                               |
| `quantity` | A `modelskill.Quantity`. Crucial if metadata is missing (e.g., Pandas `DataFrame`). Often inferred from `dfs0` files with EUM info.                                                                                                                                                                                                                                         |

::: {.callout-tip title="Many PointModelResult objects can share the same name" collapse="true"}
The `name` parameter in `PointModelResult` identifies the *overall* model simulation, not a specific point. You may create several `PointModelResult` objects that all come from the *same simulation* but represent different output locations (e.g., water level at point A, discharge at point B). All these objects should share the same `name` (e.g., "Model_Run_Alpha"). This shared name signifies they originate from the same model execution. Later, when using ModelSkill's `Comparer`, you will explicitly match each of these individual `PointModelResult` objects to its corresponding `Observation` object.
:::

### From Dataset

First, read a `dfs0` file with model output into a MIKE IO `Dataset`.
```{python}
ds_model_data = mikeio.read("data/model_results.dfs0")
ds_model_data
```

Create the `PointModelResult` from the `Dataset`. `name` identifies the model simulation. `quantity` is often inferred from `dfs0` files with EUM information.
```{python}
mod_116l1_dataset = ms.PointModelResult(
    data=ds_model_data,
    item="reach:Discharge:116l1:37.651",       # Item name from the dfs0
    name="MIKE+_RunA",                         # Model simulation identifier
)
mod_116l1_dataset
```

Like with observations, the `PointModelResult` object has useful attributes and methods. For example, plot to verify:
```{python}
mod_116l1_dataset.plot()
```

### From dfs0 file

Create a `PointModelResult` using the `dfs0` file path directly.
```{python}
mod_12l1_file = ms.PointModelResult(
    data="data/model_results.dfs0",
    item="reach:Discharge:12l1:28.410",
    name="MIKE+_RunA",                      # Same simulation as above, different location/item
)
mod_12l1_file.to_dataframe().head()
```

### From Pandas DataFrame

First, prepare a Pandas `DataFrame` with model data. This example reads a `dfs0` file into a DataFrame.
```{python}
df_model = mikeio.read("data/model_results.dfs0").to_dataframe()
df_model.head()
```

Create a `PointModelResult` from the `DataFrame`. Provide `quantity` as DataFrames lack EUM information.
```{python}
mod_116l1_df = ms.PointModelResult(
    data=df_model,
    item="reach:Discharge:116l1:37.651",            # Column name in the DataFrame
    name="MIKE+_RunA",                                   # Identifies the overall model simulation
    quantity=ms.Quantity(name="Discharge", unit="m^3/s"),
)
mod_116l1_df.plot()
```

### From res1d file

MIKE+ `res1d` files store results for an entire network. For point comparisons with `PointObservation` in ModelSkill, first extract the specific time series for the point(s) into an intermediate format (e.g., `dfs0` file, Pandas DataFrame). This example extracts one model output point to a `dfs0` file, then creates a `PointModelResult`.

First, extract model output (one point, one variable) to a `dfs0` file.
```{python}
res = mikeio1d.open("data/network.res1d")
res.reaches["116l1"]["37.651"].Discharge.to_dfs0("data/model_Q_116l1.dfs0")
ds = mikeio.read("data/model_Q_116l1.dfs0")
ds
```
Now, create a `PointModelResult` from this new `dfs0` file. Use the item name from the `Dataset` object created above.

```{python}
mod_116l1 = ms.PointModelResult(
    data=ds,
    item="reach:Discharge:116l1:37.651",
    name="MIKE+",
)
mod_116l1.plot() # Verify
```
```{python}
#| echo: false
#| output: false
# Clean up the created dfs0 file
if os.path.exists("data/model_Q_116l1.dfs0"):
    os.remove("data/model_Q_116l1.dfs0")
```

::: {.callout-tip title="Future: better integration of res1d with ModelSkill" collapse="true"}
Future versions of ModelSkill may allow creating a *network* result, instead of a *point* result. This would allow network results to automatically be matched with corresponding observations, eliminating the need to manually match individual model result points with observation points.
:::

## Best Practices

Consistent data organization and naming are key.

-   **Organize Data:** Structure observation and model result files (e.g., separate folders, clear names). This helps when programmatically accessing many files.
-   **Descriptive Names:** Use `name` in `PointObservation` and `PointModelResult` for clear identifiers (e.g., `PointObservation(name="Flow_Gauge_West")`). This aids in managing objects, improves plot clarity, and helps programmatic creation with many observations or runs.
-   **Specify Units and Quantities:** Always provide `quantity` for sources like DataFrames or CSVs. ModelSkill often infers this from `dfs0` files with EUM information. Correct metadata is crucial for comparisons, visualizations, and automated workflows. See the `modelskill.Quantity` callout and official documentation.

::: {.callout-tip title="Beyond points: Exploring other data types in ModelSkill" collapse="true"}
ModelSkill is versatile. This section focuses on point data, but the package also supports `TrackObservation` (data along a path) and `GridObservation` (gridded data). These are useful for different validation scenarios. See the [official documentation](https://dhi.github.io/modelskill/) for examples and use cases.
:::